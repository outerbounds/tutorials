{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0448702f-9b61-447b-9285-5b3c1b618e0e",
   "metadata": {},
   "source": [
    "This episode references this [notebook](https://github.com/outerbounds/tutorials/blob/main/cv/cv-intro-1.ipynb). \n",
    "It shows how to access the MNIST data and train a neural network using Keras. \n",
    "You will walk through exploratory data analysis and build a basic predictive model using this famous machine learning dataset.\n",
    "After you have a model trained you will evaluate it and learn to save and reload models using the Keras framework.\n",
    "If you are already familiar with MNIST and Keras fundamentals, you may want to skip to [Episode 3](/docs/cv-tutorial-S1E3/) where Metaflow enters the tutorial.\n",
    "\n",
    "To view the content of this page in the notebook you can start the notebook with this command after following the setup instructions:\n",
    "```bash\n",
    "jupyter lab cv-intro-1.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75682f69-26f1-4ded-9eb4-c94ba6923759",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3a964f-4683-4348-aeba-86e2f1457223",
   "metadata": {},
   "source": [
    "To begin, let's access the MNIST dataset using Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a0ab6dd-f6d4-4f3f-b9a9-10b2acaeb89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "num_classes = 10\n",
    "((x_train, y_train), (x_test, y_test)) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55987eb5-24c6-48d1-8eea-300d6407a1d4",
   "metadata": {},
   "source": [
    "You will find 60000 and 10000 data instances (images) in the training and test set. \n",
    "Each image has dimensions `28x28x1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406c4612-56aa-4e37-a1cc-ce2b53bd56a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Feature Dimensions: (60000, 28, 28, 1) | Train Set Label Dimensions: (60000, 10)\n",
      "Test Set Feature Dimensions: (10000, 28, 28, 1) | Test Set Label Dimensions: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# show dataset dimensionality\n",
    "print(\"Train Set Feature Dimensions: {}\".format(x_train.shape), end = \" | \")\n",
    "print(\"Train Set Label Dimensions: {}\".format(y_train.shape))\n",
    "print(\"Test Set Feature Dimensions: {}\".format(x_test.shape), end = \" | \")\n",
    "print(\"Test Set Label Dimensions: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df20f8f0-70a6-4ab1-b9be-116f19bd14df",
   "metadata": {},
   "source": [
    "The images are of handwritten digits that look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47b5dba-3e17-4596-9f58-9b3cd1cfa1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "N_ROWS = N_COLS = 3\n",
    "out_path = './mnist_random_image_grid.png'\n",
    "\n",
    "plt.ioff()\n",
    "fig,ax = plt.subplots(N_ROWS, N_COLS, figsize=(8,8))\n",
    "for i in range(N_ROWS):\n",
    "    for j in range(N_COLS):\n",
    "        idx = np.random.randint(low=0, high=x_train.shape[0])\n",
    "        ax[i,j].imshow(x_train[idx], cmap='gray')\n",
    "        ax[i,j].axis('off')\n",
    "fig.suptitle(\"Random Images from the Training Set\", fontsize=22, y=.98)\n",
    "fig.tight_layout()\n",
    "fig.savefig(out_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985c5ec-2bcf-4df6-bf4e-db81543aed46",
   "metadata": {},
   "source": [
    "![](./mnist_random_image_grid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40be68b-cef1-4fae-87b0-606a487f3712",
   "metadata": {},
   "source": [
    "Since this is a [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning) task, the data instances are labeled. \n",
    "The learning task is to predict the correct label out of the 10 possibilities. \n",
    "\n",
    "\n",
    "In the `y_train` and `y_test` objects, you will see 10 dimensions for each data instance. \n",
    "For each of these records, one of the ten dimensions will be a `1` and all others will be a `0`. \n",
    "You can verify this with the following assertion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2b93795-4d2b-461c-b458-028bed85907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(y_test.sum(axis=1) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba2255d-73a9-4004-9701-289c6f3082b0",
   "metadata": {},
   "source": [
    "Finally, you can view the distribution over true class labels to see that this dataset is relatively balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa0ed08f-16c6-4a9e-ab7d-20eea827ae83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddie/Dev/outerbounds-docs/docs/docs-env/lib/python3.9/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col_name, dtype in df.dtypes.iteritems():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-597ff949442e4121b369bcff53dbe57d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-597ff949442e4121b369bcff53dbe57d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-597ff949442e4121b369bcff53dbe57d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-9277bcd9f4bddac95b6961c719f70a82\"}, \"mark\": \"bar\", \"encoding\": {\"tooltip\": [{\"field\": \"Class\", \"type\": \"quantitative\"}, {\"field\": \"Count\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Count\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Class\", \"type\": \"ordinal\"}}, \"height\": 300, \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-9277bcd9f4bddac95b6961c719f70a82\": [{\"Class\": 0, \"Count\": 980.0}, {\"Class\": 1, \"Count\": 1135.0}, {\"Class\": 2, \"Count\": 1032.0}, {\"Class\": 3, \"Count\": 1010.0}, {\"Class\": 4, \"Count\": 982.0}, {\"Class\": 5, \"Count\": 892.0}, {\"Class\": 6, \"Count\": 958.0}, {\"Class\": 7, \"Count\": 1028.0}, {\"Class\": 8, \"Count\": 974.0}, {\"Class\": 9, \"Count\": 1009.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(y_test.sum(axis=0), columns=['Count'])\n",
    "df.index.name = 'Class'\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "alt.Chart(df).mark_bar().encode(\n",
    "    x='Count:Q',\n",
    "    y=\"Class:O\",\n",
    "    tooltip=['Class', 'Count']\n",
    ").properties(height=300, width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a33a9e3-852d-4222-8014-c0d81ca4c9e3",
   "metadata": {},
   "source": [
    "### Fit a Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ec71d9-d988-4dfa-982d-15e7551314a2",
   "metadata": {},
   "source": [
    "Before training a model, it is useful to set a baseline. A common baseline for classification tasks is the majority-class classifier, which measures what happens when all of the data instances are predicted to be from the majority class. This pattern is demonstrated in our [NLP tutorial](/docs/nlp-tutorial-overview/). However, for the MNIST dataset and the corresponding image classification task described above, the majority class-classifier will lead to a baseline model that predicts correctly just over 10% of the time. This is not a very useful baseline. Instead, let's build a feedforward neural network to compare to a more advanced convolutional neural network you will build later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffab54af-6824-48f6-9a4e-3d1f501840e5",
   "metadata": {},
   "source": [
    "### Configure Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da16ab5-2965-4ef2-92a3-b8cf58a17306",
   "metadata": {},
   "source": [
    "These variables represent some training settings and the model's hyperparameters. \n",
    "Don't worry if you are unfamiliar with neural networks or what these words mean.\n",
    "If you do know what they are, feel free to experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f9a100a-4029-49d4-9afa-7506479d67f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential, Input\n",
    "\n",
    "num_pixels = 28 * 28\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "kernel_initializer = 'normal'\n",
    "optimizer = 'adam'\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "epochs = 3\n",
    "batch_size = 32\n",
    "verbose = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69a2b2e-f1a0-4725-aa75-a393e0794bf7",
   "metadata": {},
   "source": [
    "### Build a Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597a0270-88ac-4f46-b5f2-8b8475e0fd23",
   "metadata": {},
   "source": [
    "Next, let's construct a Keras model adding `layers`. \n",
    "The Keras `layers` apply matrix operations to data as it moves toward the output layer of the neural network.\n",
    "In this case, we use two `Dense` layers. `Dense` means they are feed-forward, fully-connected layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb4a0efc-663b-41f3-b39e-82d60305a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Dense(\n",
    "    num_pixels, input_dim=num_pixels,\n",
    "    kernel_initializer=kernel_initializer,\n",
    "    activation='relu'\n",
    "))\n",
    "model.add(layers.Dense(\n",
    "    num_classes,\n",
    "    kernel_initializer=kernel_initializer,\n",
    "    activation='softmax'\n",
    "))\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9738cd69-6895-4339-98d1-bbb150b2579e",
   "metadata": {},
   "source": [
    "### Train Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fe541a-c209-447c-b583-5ad51a3be32d",
   "metadata": {},
   "source": [
    "To work with the feed-forward network you need to reshape the images. \n",
    "This is done by flattening the matrix representing the images into a one-dimensional vector with length `num_pixels`. \n",
    "Notice that this is the same value as the `input_dim` of the first `layer` in the neural network you defined in the last step. \n",
    "Once the data is ready, we can pass it to the `model.fit` function and train a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e56be9-f931-4e70-9241-4abd3a60862a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 13:09:45.505250: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 - 5s - loss: 0.1911 - accuracy: 0.9434 - val_loss: 0.0991 - val_accuracy: 0.9687 - 5s/epoch - 3ms/step\n",
      "Epoch 2/3\n",
      "1875/1875 - 4s - loss: 0.0753 - accuracy: 0.9768 - val_loss: 0.0743 - val_accuracy: 0.9768 - 4s/epoch - 2ms/step\n",
      "Epoch 3/3\n",
      "1875/1875 - 5s - loss: 0.0480 - accuracy: 0.9843 - val_loss: 0.0809 - val_accuracy: 0.9766 - 5s/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "_x_train = x_train.reshape(x_train.shape[0], num_pixels).astype('float32')\n",
    "_x_test = x_test.reshape(x_test.shape[0], num_pixels).astype('float32')\n",
    "history = model.fit(\n",
    "    _x_train, y_train,\n",
    "    validation_data = (_x_test, y_test),\n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size,\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc04fa2-569e-4d1d-8bb4-5bc9f253d620",
   "metadata": {},
   "source": [
    "### Evaluate the Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4205eeb-0b94-4c12-a4eb-603f6244dc67",
   "metadata": {},
   "source": [
    "After training the model you will want to evaluate its performance to see if it's ability to generalize is improving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "500b8011-6d5f-4eb1-a597-67adbdc8a79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicted correctly 97.66% of the time on the test set.\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(\n",
    "    x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2]).astype('float32'),\n",
    "    y_test,\n",
    "    verbose=0\n",
    ")\n",
    "categorical_cross_entropy = scores[0]\n",
    "accuracy = scores[1]\n",
    "msg = \"The model predicted correctly {}% of the time on the test set.\"\n",
    "print(msg.format(round(100*accuracy, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb4ba46-2a09-4a95-9651-114e7b242a9d",
   "metadata": {},
   "source": [
    "### Save and Load Keras Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba34207-a857-4214-906a-c329f9419d90",
   "metadata": {},
   "source": [
    "Like all software development, it is important to create robust processes for checkpointing, saving, and loading.\n",
    "This is even more important in computer vision, as model training can be expensive.\n",
    "Luckily, Keras provides utilities for saving and loading models. \n",
    "For example, you can save the model architecture, model weights, and the traced TensorFlow subgraphs of call functions with a simple `model.save` API. \n",
    "Later you will see how to incorporate this into your flows which will help you train and make predictions with models in any environment you need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8849cf47-e402-4ef2-b912-e79de1901cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test_model/assets\n"
     ]
    }
   ],
   "source": [
    "location = 'test_model'\n",
    "model.save(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead793b-f907-42cc-b51d-d5519b353dc7",
   "metadata": {},
   "source": [
    "Using `model.load` with the same location will then reload the same model object state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31fe49be-015c-4d47-a2db-5d6e76a27b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.models.load_model(location)\n",
    "scores = model.evaluate(\n",
    "    x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2]).astype('float32'),\n",
    "    y_test,\n",
    "    verbose=0\n",
    ")\n",
    "assert scores[1] > .96, \"Model should be doing better after two epochs.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c7ceb-7e29-4f78-af64-c498dc940dde",
   "metadata": {},
   "source": [
    "To learn more about your options for saving and loading Keras models please see [this guide](https://www.tensorflow.org/guide/keras/save_and_serialize). It describes cases like how to [save to the Keras H5 format](https://www.tensorflow.org/guide/keras/save_and_serialize#whole-model_saving_loading) instead of the newer SavedModel format and how to [save and load only model weights](https://www.tensorflow.org/guide/keras/save_and_serialize#saving_loading_only_the_models_weights_values).\n",
    "\n",
    "In this lesson, you explored the MNIST dataset and built a high-accuracy baseline model. In the next lesson, you will build a convolutional neural network model to see how its performance compares to the baseline. See you there! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('3.10.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "60d98827d7482d2a0f6aae287a18990d3a1d423e0f66197ec6cdef8a2e07b41f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
