{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8d44f0af-0462-4418-bc1b-20cd959d990d",
   "metadata": {},
   "source": [
    "---\n",
    "title: Recommender Systems - Episode 5\n",
    "slug: /docs/recsys-tutorial-L5/\n",
    "tags: [data, recsys]\n",
    "sidebar_label: Analyze Results and Iterate\n",
    "id: recsys-tutorial-L5\n",
    "pagination_next: tutorials/nbs/recsys/recsys-tutorial-L6\n",
    "pagination_prev: tutorials/nbs/recsys/recsys-tutorial-L4\n",
    "description: A tutorial that uses DuckDB, Gensim, Keras, and Metaflow to operationalize a machine learning workflow.\n",
    "category: data science\n",
    "hide_table_of_contents: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf93e59",
   "metadata": {},
   "source": [
    "Now that we have written and run several flows, we can use Metaflow's Client API as a handy way to fetch results, analyze performance and decide how to iterate on embeddings, modeling approaches, and experiment design. You can follow along in [this notebook](https://github.com/outerbounds/tutorials/blob/main/recsys/recsys-1.ipynb) as we load and analyze flow results, and then use [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) to produce a data visualization. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "73555d85-e442-43c6-820f-fc9e2d4697d7",
   "metadata": {},
   "source": [
    "### <NumberHeading number={1}>Accessing Results with Metaflow's Client API</NumberHeading>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207e26d3",
   "metadata": {},
   "source": [
    "First we import the packages we need and define some config variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31683e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Flow\n",
    "import numpy as np\n",
    "from random import choice\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dcdb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOW_NAME = 'RecSysTuningFlow'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a534af3",
   "metadata": {},
   "source": [
    "Let's retrieved the artifacts from the latest successful run. \n",
    "The `get_latest_successful_run` uses the `metaflow.Flow` object to get results of runs using the (class) name of your flows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3341c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_successful_run(flow_name: str):\n",
    "    \"Gets the latest successful run.\"\n",
    "    for r in Flow(flow_name).runs():\n",
    "        if r.successful: \n",
    "            return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5c4e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_run = get_latest_successful_run(FLOW_NAME)\n",
    "latest_model = latest_run.data.final_vectors\n",
    "latest_dataset = latest_run.data.final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cca044",
   "metadata": {},
   "source": [
    "First, check all is in order by printing out datasets and rows and stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042454ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>artist_sequence</th>\n",
       "      <th>track_sequence</th>\n",
       "      <th>track_test_x</th>\n",
       "      <th>track_test_y</th>\n",
       "      <th>predictions</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>3d0f759337e6aa576c75ecd3fbf14968-March 2013</td>\n",
       "      <td>[Miguel, A$AP Rocky, Drake, Justin Timberlake,...</td>\n",
       "      <td>[Miguel|||Do You..., A$AP Rocky|||F**kin' Prob...</td>\n",
       "      <td>[Miguel|||Do You..., A$AP Rocky|||F**kin' Prob...</td>\n",
       "      <td>Bruno Mars|||When I Was Your Man</td>\n",
       "      <td>[Justin Timberlake|||Strawberry Bubblegum, Jus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10837</th>\n",
       "      <td>cf1a043e8f7f6fe0d8d2741e1791e4bb-float shuffle...</td>\n",
       "      <td>[P!nk, Amy Winehouse, Sara Bareilles, The Chem...</td>\n",
       "      <td>[P!nk|||'Cuz I Can, Amy Winehouse|||'Round Mid...</td>\n",
       "      <td>[P!nk|||'Cuz I Can, Amy Winehouse|||'Round Mid...</td>\n",
       "      <td>Beifus|||lava</td>\n",
       "      <td>[This Mortal Coil|||Song To The Siren, The Che...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6140</th>\n",
       "      <td>cae6ff399c07ca2b9e2f3a47f5175958-Cheap Diamonds</td>\n",
       "      <td>[Phoenix, The Neighbourhood, St. Lucia, Panic!...</td>\n",
       "      <td>[Phoenix|||1901, The Neighbourhood|||Afraid, S...</td>\n",
       "      <td>[Phoenix|||1901, The Neighbourhood|||Afraid, S...</td>\n",
       "      <td>Sir Sly|||You Haunt Me</td>\n",
       "      <td>[Hillsong Young &amp; Free|||Wake - Live, Robbie W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             playlist_id  \\\n",
       "3716         3d0f759337e6aa576c75ecd3fbf14968-March 2013   \n",
       "10837  cf1a043e8f7f6fe0d8d2741e1791e4bb-float shuffle...   \n",
       "6140     cae6ff399c07ca2b9e2f3a47f5175958-Cheap Diamonds   \n",
       "\n",
       "                                         artist_sequence  \\\n",
       "3716   [Miguel, A$AP Rocky, Drake, Justin Timberlake,...   \n",
       "10837  [P!nk, Amy Winehouse, Sara Bareilles, The Chem...   \n",
       "6140   [Phoenix, The Neighbourhood, St. Lucia, Panic!...   \n",
       "\n",
       "                                          track_sequence  \\\n",
       "3716   [Miguel|||Do You..., A$AP Rocky|||F**kin' Prob...   \n",
       "10837  [P!nk|||'Cuz I Can, Amy Winehouse|||'Round Mid...   \n",
       "6140   [Phoenix|||1901, The Neighbourhood|||Afraid, S...   \n",
       "\n",
       "                                            track_test_x  \\\n",
       "3716   [Miguel|||Do You..., A$AP Rocky|||F**kin' Prob...   \n",
       "10837  [P!nk|||'Cuz I Can, Amy Winehouse|||'Round Mid...   \n",
       "6140   [Phoenix|||1901, The Neighbourhood|||Afraid, S...   \n",
       "\n",
       "                           track_test_y  \\\n",
       "3716   Bruno Mars|||When I Was Your Man   \n",
       "10837                     Beifus|||lava   \n",
       "6140             Sir Sly|||You Haunt Me   \n",
       "\n",
       "                                             predictions  hit  \n",
       "3716   [Justin Timberlake|||Strawberry Bubblegum, Jus...    0  \n",
       "10837  [This Mortal Coil|||Song To The Siren, The Che...    0  \n",
       "6140   [Hillsong Young & Free|||Wake - Live, Robbie W...    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c66fd86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2172"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(latest_dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc552aa0-9937-48e2-80e8-196064f5a69e",
   "metadata": {},
   "source": [
    "### <NumberHeading number={2}>Iterative Model Development Workflow</NumberHeading>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9a16f5",
   "metadata": {},
   "source": [
    "Now, let's turn our attention to the model - the embedding space we trained: let's check how big it is and use it to make a test prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3624001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# track vectors in the space: 27419\n",
      "Example track: 'The Box Tops|||The Letter'\n",
      "Test vector for 'The Box Tops|||The Letter': [-0.58819056  0.14980857  0.58946514 -0.21597098  1.6484333 ]\n",
      "Similar songs to 'The Box Tops|||The Letter': [('The Rolling Stones|||The Last Time', 0.9870179891586304), ('B.B. King|||The Thrill Is Gone', 0.9854589104652405), ('The Platters|||The Great Pretender', 0.9850826859474182)]\n"
     ]
    }
   ],
   "source": [
    "print(\"# track vectors in the space: {}\".format(len(latest_model)))\n",
    "test_track = choice(list(latest_model.index_to_key))\n",
    "print(\"Example track: '{}'\".format(test_track))\n",
    "test_vector = latest_model[test_track]\n",
    "print(\"Test vector for '{}': {}\".format(test_track, test_vector[:5]))\n",
    "test_sims = latest_model.most_similar(test_track, topn=3)\n",
    "print(\"Similar songs to '{}': {}\".format(test_track, test_sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a49683",
   "metadata": {},
   "source": [
    "The skip-gram model we trained is an embedding space: if we did our job correctly, the space is such that tracks closer in the space are actually similar, and tracks that are far apart are pretty unrelated.\n",
    "\n",
    "[Judging the quality of \"fantastic embeddings\" is hard](https://arxiv.org/abs/2007.14906), but we point here to some common qualitative checks you can run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dadd3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar songs to 'Daft Punk|||Get Lucky - Radio Edit': [(\"deadmau5|||Ghosts 'n' Stuff - feat. Rob Swire\", 0.9701901078224182), ('PSY|||Gangnam Style (강남스타일)', 0.9514472484588623), ('PSY|||Gentleman', 0.9451815485954285)]\n"
     ]
    }
   ],
   "source": [
    "# qualitative check, make sure to change with a song that is in the set\n",
    "test_track = 'Daft Punk|||Get Lucky - Radio Edit'\n",
    "test_sims = latest_model.most_similar(test_track, topn=3)\n",
    "print(\"Similar songs to '{}': {}\".format(test_track, test_sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d59cc5",
   "metadata": {},
   "source": [
    "If you use 'Daft Punk|||Get Lucky - Radio Edit' as the query item in the space, you will discover a pretty interesting phenomenon, that is, that there are unfortunately many duplicates in the datasets, that is, songs which are technically different but semantically the same, i.e. Daft Punk|||Get Lucky - Radio Edit vs Daft Punk|||Get Lucky.\n",
    "\n",
    "This is a problem as i) working with dirty data may be misleading, and ii) these issues make data sparsity worse, so the task for our model is now harder. That said, it is cool that KNN can be used to quickly identify and potentially remove duplicates, depending on your dataset and use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0711636",
   "metadata": {},
   "source": [
    "Let's map some tracks to known categories: the intuition is that songs that are similar will be colored in the same way in the chart, and so we will expect them to be close in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54fb335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_sequence = latest_dataset['track_sequence'] \n",
    "songs = [item for sublist in track_sequence for item in sublist]\n",
    "song_counter = Counter(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3030758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we downsample the vector space a bit to the K most common songs to avoid crowding the plot / analysis\n",
    "TOP_N_TRACKS = 250\n",
    "top_tracks = [_[0] for _ in song_counter.most_common(TOP_N_TRACKS)]\n",
    "tracks = [_ for _ in latest_model.index_to_key if _ in top_tracks]\n",
    "\n",
    "assert TOP_N_TRACKS == len(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4339d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is the generic \"unnamed\" category\n",
    "tracks_to_category = {t: 'unknown' for t in tracks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d506251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we tag songs based on keywords found in the playlist name. Of course, better heuristics are possible ;-)\n",
    "all_playlists_names = set(latest_dataset['playlist_id'].apply(lambda r: r.split('-')[1].lower().strip()))\n",
    "target_categories = [\n",
    "    'rock',\n",
    "    'rap',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cd7e54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rock\n",
      "4\n",
      "Processing rap\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# while not pretty, this select the playlists with the target keyword, and mark the tracks\n",
    "# as belonging to that category\n",
    "\n",
    "def tag_tracks_with_category(_df, target_word, tracks_to_category):\n",
    "    _df = _df[_df['playlist_id'].str.contains(target_word)]\n",
    "    # debug\n",
    "    print(len(_df))\n",
    "    # unnest the list\n",
    "    songs = [item for sublist in _df['track_sequence'] for item in sublist]\n",
    "    for song in songs:\n",
    "        if song in tracks_to_category and tracks_to_category[song] == 'unknown':\n",
    "            tracks_to_category[song] = target_word\n",
    "    \n",
    "    return tracks_to_category\n",
    "\n",
    "\n",
    "for cat in target_categories:\n",
    "    print(\"Processing {}\".format(cat))\n",
    "    tracks_to_category = tag_tracks_with_category(latest_dataset, cat, tracks_to_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da3639e",
   "metadata": {},
   "source": [
    "Note: to visualize a n-dimensional space, we need to be in 2D. We can use a dimensionality reduction technique like [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acdf4140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_analysis(embeddings, perplexity=50, n_iter=1000):\n",
    "    \"\"\"\n",
    "    TSNE dimensionality reduction of track embeddings - it may take a while!\n",
    "    \"\"\"\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, n_iter=n_iter, verbose=1, learning_rate='auto', init='random')\n",
    "\n",
    "    return tsne.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d6cdb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "# add all the tagged tracks to the embedding space, on top of the popular tracks\n",
    "for track, cat in tracks_to_category.items():\n",
    "    # add a track if we have a tag, if not there already, if we have a vector for it\n",
    "    if cat in target_categories and track in latest_model.index_to_key and track not in tracks:\n",
    "        tracks.append(track)\n",
    "    \n",
    "print(len(tracks)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72bfddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 48)\n",
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 250 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 250 samples in 0.006s...\n",
      "[t-SNE] Computed conditional probabilities for sample 250 / 250\n",
      "[t-SNE] Mean sigma: 6.607835\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 48.096527\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.297004\n"
     ]
    }
   ],
   "source": [
    "#meta:filter_words=sklearn\n",
    "# extract the vectors from the model and project them in 2D\n",
    "embeddings = np.array([latest_model[t] for t in tracks])\n",
    "# debug, print out embedding shape\n",
    "print(embeddings.shape)\n",
    "tsne_results = tsne_analysis(embeddings)\n",
    "assert len(tsne_results) == len(tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f30c3-e3a3-4b44-a220-f8a7ca4f22f3",
   "metadata": {},
   "source": [
    "Now we can define a function to plot the 2D representations produced by the TSNE algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daf6bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatterplot_with_lookup(\n",
    "    title: str, \n",
    "    items: list, \n",
    "    items_to_target_cat: dict,\n",
    "    vectors: list,\n",
    "    output_path: str = './song_TSNE.png'\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the 2-D vectors in the space, and use the mapping items_to_target_cat\n",
    "    to color-code the points for convenience\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.ioff()\n",
    "    \n",
    "    groups = {}\n",
    "    for item, target_cat in items_to_target_cat.items():\n",
    "        if item not in items:\n",
    "            continue\n",
    "\n",
    "        item_idx = items.index(item)\n",
    "        x = vectors[item_idx][0]\n",
    "        y = vectors[item_idx][1]\n",
    "        if target_cat in groups:\n",
    "            groups[target_cat]['x'].append(x)\n",
    "            groups[target_cat]['y'].append(y)\n",
    "        else:\n",
    "            groups[target_cat] = {\n",
    "                'x': [x], 'y': [y]\n",
    "                }\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    for group, data in groups.items():\n",
    "        ax.scatter(data['x'], data['y'], \n",
    "                   alpha=0.1 if group == 'unknown' else 0.8, \n",
    "                   edgecolors='none', \n",
    "                   s=25, \n",
    "                   marker='o',\n",
    "                   label=group)\n",
    "        \n",
    "    [ax.spines[dir].set_visible(False) for dir in ['top', 'bottom', 'left', 'right']]\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=2)\n",
    "    fig.savefig(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d51f662",
   "metadata": {},
   "source": [
    "Finally, we are ready to plot the latent space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe80b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatterplot_with_lookup(\n",
    "    'Music in (latent) space', \n",
    "    tracks, \n",
    "    tracks_to_category, \n",
    "    tsne_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05638fe-784b-4129-8676-631f0bcb957b",
   "metadata": {},
   "source": [
    "![](./song_TSNE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f01147b-a076-407d-999f-8a892969439f",
   "metadata": {},
   "source": [
    "So far, you have trained embeddings and models, tuned them to find the most promising candidates, and analyzed the results using Metaflow's Client API. In the final episode of this tutorial, we will make another `FlowSpec` object that shows how you can combine these processes with Sagemaker's convenient deployment tools. The end result will be a recommender system you can use to serve real-time predictions about what song to suggest next to a user of an app. See you there!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
