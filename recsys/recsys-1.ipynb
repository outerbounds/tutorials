{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4155ccdc-11cd-4cab-9951-579db9acb80c",
   "metadata": {},
   "source": [
    "Before diving deep into Metaflow, this lesson will introduce our problem and do a preliminary analysis of our dataset. \n",
    "You can follow along in [this notebook](https://github.com/outerbounds/tutorials/blob/main/recsys/recsys-1.ipynb) if you want to run the code yourself. You will learn a little bit about recommender systems, the kinds of data the flow through them, and then you will be introduced to a Spotify playlist dataset that the rest of the tutorial will build a next song recommender system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017e960-c610-47c0-901b-1b5eb114235e",
   "metadata": {},
   "source": [
    "### RecSys 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b95dd6-73b3-4342-9b67-16c70eb4436a",
   "metadata": {},
   "source": [
    "Recommender systems (RSs) are some of the most ubiquitous ML systems in production: whether Netflix suggesting you what movie to watch, Amazon what books to buy, or Linkedin which data influencer to follow, RSs play a pivotal role in our digital life (it is estimated the RSs market will be around 15BN in 2026!).\n",
    "\n",
    "The model architecture, and therefore many MLOps choices, of a given RS, depends heavily on the use case. While a full taxonomy is beyond the scope of this tutorial, we can provide a simple taxonomy of RSs based on the type of input and output they process.\n",
    "\n",
    "![](/assets/recsys-io-taxonomy.png)\n",
    "\n",
    "1. input user, output item - example: Netflix recommends you a movie that they think you would enjoy;\n",
    "2. input item, output item - example: while browsing a book page, Amazon recommends you another book because \"people often look at X as well\";\n",
    "3. input a list of items, output the next items - Spotify is picking songs to suggest in your discover weekly playlist based on what songs you have listened to lately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e65340-e8d8-483d-b878-653053ef446a",
   "metadata": {},
   "source": [
    "Finally, as far as input data goes, there is important distinction practitioners make between content and behavioral data.\n",
    "\n",
    "![](/assets/content-and-behavioral-data.png)\n",
    "\n",
    "Content data is data that does not depend on any interaction: think for example of the author of a book on Amazon, or a movie poster on Netflix - even if nobody will ever watch that movie, we could still use some basic metadata to decide how likely we are to like it. Behavioral data is the result of user interactions with a system: it may be add-to-cart events for e-commerce or previous people you added on Facebook - generally speaking, behavioral data needs systems in place to capture and store these signals, often under time constraints.\n",
    "\n",
    "While the general rule of ML applies and more data is better, in practice the use case and modeling technique(s) will constrain what is feasible: for example, if you are building a RS for a completely new product, with 0 or few active users, content-based data is your only option! The trick to building a recommender system for a product is to be able to ship something that is good enough to generate interest in the product, so over time you can build an increasingly useful behavioral dataset as the product improves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a0744-4cdf-46e6-b3d6-97e8ca0cf5a1",
   "metadata": {},
   "source": [
    "### Next Event Prediction for Songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1416b95f-1806-44f9-be27-e260a0ce4db5",
   "metadata": {},
   "source": [
    "Armed with our taxonomy, we can explore what is the use case we are trying to solve today:\n",
    "\n",
    "_Can we suggest what to listen to next when presented with a song?_\n",
    "\n",
    "You will build a sequential recommender system that matches case 3 above. The model will learn from existing sequences (playlists by real users) how to continue extending an arbitrary new list. More generally, this task is also known as next event prediction (NEP). The modeling technique we picked will only leverage behavioral data in the form of interactions created by users when composing their playlists.\n",
    "\n",
    "The training set is a list of playlists, e.g.:\n",
    "* song_1, song_414, song_42425\n",
    "* song_412, song_2214, song_525, song_11, song_414, song_42425\n",
    "* song_12, song_416\n",
    "* ...\n",
    "\n",
    "The key intuition about our modeling is that \"songs that often appear in similar contexts\" are similar. If we observe that \"Imagine\" and \"Hey Jude\" tend to appear in similar playlists, they must have something in common!\n",
    "\n",
    "At prediction time, our input will be an unseen playlist with N songs: we will take the first N - 1 songs as the input (or query) for our model, and ask it to predict the last, missing item, that is:\n",
    "\n",
    "* song_525, song_22, song_814, song_4255\n",
    "\n",
    "will become:\n",
    "\n",
    "* query: song_525, song_22, song_814\n",
    "* label: song_4255\n",
    "\n",
    "If our model is able to guess \"song_4255\", we will count it as a successful prediction. Of course, we have left all the juicy details out - so no worries if things feel a bit vague: for now, we just want to be very clear about what problem we are solving, and which type of input/output data our model should deal with.\n",
    "\n",
    "In the rest of the notebook, we will read our dataset and start getting familiar with the main entities of characters of our story, tracks, and playlists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a9f2f-2509-4eb9-bec5-b077a1bf4116",
   "metadata": {},
   "source": [
    "### Download the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425dc5c7-b6de-4360-bf48-487a78f33df1",
   "metadata": {},
   "source": [
    "You can download the dataset from Kaggle [here](https://www.kaggle.com/datasets/andrewmvd/spotify-playlists?resource=download).\n",
    "Place the downloaded file in the `recsys` directory and unzip it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3060b-acb4-4ce6-a8ff-6a6eb04e3d98",
   "metadata": {},
   "source": [
    "```\n",
    "unzip ./archive.zip\n",
    "rm ./archive.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcba516-c4bf-4f88-97fd-2d45979a91f6",
   "metadata": {},
   "source": [
    "We need to do so minor data cleaning, which can be handled by running the following script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2204f30a-52f7-4c31-a44a-ff3e51363c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row_id  ...        playlist\n",
      "0       0  ...  HARD ROCK 2010\n",
      "1       1  ...  HARD ROCK 2010\n",
      "2       2  ...  HARD ROCK 2010\n",
      "3       3  ...  HARD ROCK 2010\n",
      "4       4  ...  HARD ROCK 2010\n",
      "\n",
      "[5 rows x 5 columns]\n",
      "Total rows: 12891680\n",
      "All done\n",
      "\n",
      "See you, space cowboy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! python clean_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f321b9-0277-4e68-b634-b931ebea62c0",
   "metadata": {},
   "source": [
    "### What does the Data Look Like?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf3dd7c-12ea-4419-bc19-1e3bc58fc801",
   "metadata": {},
   "source": [
    "Before loading the data, there are a few packages to import: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45484c0f-6e2c-40db-98f2-bea7e56454cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import powerlaw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97965b68-ece3-4c45-be7b-ee4131e858fa",
   "metadata": {},
   "source": [
    "Now we can load the dataset and explore its structure. The dataset is stored in a `.parquet` file. [Loading parquet files into dataframes](/docs/load-parquet-data-to-pandas-df/) is a common pattern when working with large tabular datasets like the kind often found in RSs. If you are curious, we have a post all about common [file formats for tabular datasets](/docs/tabular-file-formats/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2fb0fdd-97bb-45e5-a37a-1655d66f6123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>track</th>\n",
       "      <th>playlist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
       "      <td>Elvis Costello</td>\n",
       "      <td>(The Angels Wanna Wear My) Red Shoes</td>\n",
       "      <td>HARD ROCK 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
       "      <td>Elvis Costello &amp; The Attractions</td>\n",
       "      <td>(What's So Funny 'Bout) Peace, Love And Unders...</td>\n",
       "      <td>HARD ROCK 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9cc0cfd4d7d7885102480dd99e7a90d6</td>\n",
       "      <td>Tiffany Page</td>\n",
       "      <td>7 Years Too Late</td>\n",
       "      <td>HARD ROCK 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                           user_id                            artist  \\\n",
       "0       0  9cc0cfd4d7d7885102480dd99e7a90d6                    Elvis Costello   \n",
       "1       1  9cc0cfd4d7d7885102480dd99e7a90d6  Elvis Costello & The Attractions   \n",
       "2       2  9cc0cfd4d7d7885102480dd99e7a90d6                      Tiffany Page   \n",
       "\n",
       "                                               track        playlist  \n",
       "0               (The Angels Wanna Wear My) Red Shoes  HARD ROCK 2010  \n",
       "1  (What's So Funny 'Bout) Peace, Love And Unders...  HARD ROCK 2010  \n",
       "2                                   7 Years Too Late  HARD ROCK 2010  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('cleaned_spotify_dataset.parquet')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82ebf7c-c890-4698-b5c8-0b1490d63190",
   "metadata": {},
   "source": [
    "How many data samples are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd713360-212d-4a86-a806-306f745bc57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12891680"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198669a5-4f9c-4577-8e1f-bcb56594a4cb",
   "metadata": {},
   "source": [
    "What artists and songs are most popular?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6069975a-9223-4998-a367-2665ad938c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top artists: [('Daft Punk', 36086), ('Coldplay', 35485), (None, 33568), ('Radiohead', 31429), ('The Rolling Stones', 30832), ('Kanye West', 29111), ('JAY Z', 28928), ('Eminem', 28894), ('Queen', 28079), ('David Bowie', 27802), ('Michael Jackson', 26336), ('Muse', 24159), ('U2', 23455), ('Rihanna', 23315), ('Arctic Monkeys', 23288), ('Pearl Jam', 23085), ('Foo Fighters', 21999), ('David Guetta', 21798), ('Bruce Springsteen', 21764), ('Nirvana', 21184)]\n",
      "\n",
      "\n",
      "Top songs: [('Intro', 6676), ('Home', 5600), ('Closer', 3549), ('Runaway', 3350), ('Hold On', 3224), ('Radioactive', 3189), ('Forever', 3055), ('Stay', 2993), ('Alive', 2936), ('Wake Me Up', 2794), ('Heaven', 2793), ('Trouble', 2789), ('Kids', 2714), ('Breathe', 2696), ('Crazy', 2692), ('Dreams', 2691), ('Angel', 2683), ('Happy', 2660), ('You', 2645), ('One', 2622)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artist_counter = Counter(list(df['artist']))\n",
    "song_counter = Counter(list(df['track']))\n",
    "print(\"\\nTop artists: {}\\n\".format(artist_counter.most_common(20)))\n",
    "print(\"\\nTop songs: {}\\n\".format(song_counter.most_common(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af6d59-5ac3-4385-a88c-77643f47f760",
   "metadata": {},
   "source": [
    "Let's visualize the distribution of tracks and artist in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aec7cc63-c057-4fa6-b4dc-580c2eb77548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(artists, tracks, n_bins: int=50, outpath = './artist-track-dist.png'):\n",
    "    \"\"\"\n",
    "    Plot distributions of tracks and artists in the final dataset.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from itertools import product\n",
    "    import seaborn as sns\n",
    "    sns.set_style()\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.ioff()\n",
    "    fig, axs = plt.subplots(1, 2, tight_layout=True, figsize=(8,4))\n",
    "    axs[0].hist(artist_counter.values(), bins=n_bins, color='#2E3454')\n",
    "    axs[0].set_title('Artists', fontsize=16)\n",
    "    axs[0].set_yscale('log')\n",
    "    axs[0].ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "    axs[0].set_xlabel('# of artists')\n",
    "    axs[0].set_ylabel('# of times artist is in a playlist')\n",
    "    axs[1].hist(song_counter.values(), bins=n_bins, color='#2E3454')\n",
    "    axs[1].set_title('Songs', fontsize=16)\n",
    "    axs[1].set_yscale('log')\n",
    "    axs[1].ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "    axs[1].set_xlabel('# of songs')\n",
    "    axs[1].set_ylabel('# of times song is in a playlist')\n",
    "    for (i,side) in list(product([0,1], ['top', 'right'])):\n",
    "        axs[i].spines[side].set_visible(False)\n",
    "    fig.savefig(outpath)\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f54b0b53-0741-438c-aa48-3471ac7cb9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution(artist_counter, song_counter);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798c1a05-de3b-4c27-b4a2-31ef5843a79c",
   "metadata": {},
   "source": [
    "![](artist-track-dist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b228100-3641-4f20-af65-ada089208292",
   "metadata": {},
   "source": [
    "Since it looks like our data is very skewed, we can use the `powerlaw` library and formally compare the distribution of how artists are represented in playlists to a powerlaw. Specifically, we use the package to visualize the [probability density function](https://pythonhosted.org/powerlaw/#powerlaw.Fit.plot_pdf) for the theoretical distribution estimated using the number of times artists are represented in playlists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9991f31-db4d-460e-94a9-3c6d36ae7416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating best minimal value for power law fit\n",
      "xmin progress: 99%\r"
     ]
    }
   ],
   "source": [
    "data = list(artist_counter.values())\n",
    "fit = powerlaw.Fit(data, discrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfd1c69c-8e40-406a-8f83-179ce3960a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating best minimal value for power law fit\n",
      "xmin progress: 99%\r"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(4,4))\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "data = list(artist_counter.values())\n",
    "fit = powerlaw.Fit(data, discrete=True)\n",
    "figCCDF = fit.plot_pdf(color='#2E3454', linewidth=2, ax=ax)\n",
    "fit.power_law.plot_pdf(color='#2E3454', linestyle='--', ax=figCCDF)\n",
    "fig.savefig('./powerlaw.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94188927-e06d-4ae2-92e8-e13fad324460",
   "metadata": {},
   "source": [
    "![](./powerlaw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cba104-9b9c-41b7-a42e-26ef515f84bd",
   "metadata": {},
   "source": [
    "Nice work! In this lesson, you explored a dataset with millions of Spotify songs and their playlist groupings. \n",
    "You saw which artists and songs are most popular and observed how the distribution of how artists are represented in playlists follows a power law. \n",
    "In the next episode, we will see how to leverage DuckDB to query the dataset efficiently. See you there!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mf-tutorial-recsys",
   "language": "python",
   "name": "mf-tutorial-recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
